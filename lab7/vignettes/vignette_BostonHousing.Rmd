---
title: "Vignette for caret Package"
author: "Thi Pham and Somaya Khoda Bakhsh"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = NA )
```

```{r}
library(mlbench)
library(caret)
library(leaps)
library(lab7)
data("BostonHousing")
```

This vignette use `caret` package and `ridgereg()` function to create and predict model for the `BostonHousing` data.

##1. Divide the BostonHousing data (or your own API data) into a test and training dataset using the caret package.

```{r}
data("BostonHousing")
names(BostonHousing)
train_index <- caret::createDataPartition(BostonHousing$age, p = .75,
                                         list = FALSE,
                                         times= 1)
train_data <- BostonHousing[train_index, ]
test_data <- BostonHousing[-train_index, ]


head(train_data)
head(test_data)
```


##2. Fit a linear regression model and with a linear regression model with forward selection of covariates on the training datasets.   

Fit a linear regression model: 

```{r}
ridge <- caret::train(crim~.,
                      data = train_data,
                      method='lm',
                      trControl = trainControl(method = "cv")
)

print(ridge)
```


Fitting a linear model with method = leapForward on the training dataset :
```{r}
lflmGrid <- expand.grid(nvmax=1:(ncol(train_data)-1))

ridge <- caret::train(crim~.,
                      data = train_data,
                      method='leapForward',
                      tuneGrid = lflmGrid
)
print(ridge)
```

##3. Evaluate the performance of this model on the training dataset.

Since the RMSE & MAE is low on training of lm model compared to leapForward lm where model has good perfomance with nvmax(number of predictors) we can conclude that LM is better than leapforward LM.   


##4. Fit a ridge regression model using your ridgereg() function to the training dataset for different values of lambda.


```{r}
ridge <- list(type="Regression", 
              library="lab7",
              loop=NULL,
              prob=NULL)

ridge$parameters <- data.frame(parameter="lambda",
                               class="numeric",
                               label="lambda")


ridge$grid <- function (x, y, len = NULL, search = "grid"){
  data.frame(lambda = lambda)
} 

ridge$fit <- function (x, y, wts, param, lev, last, classProbs, ...) {
  dat <- if (is.data.frame(x)) 
    x
  else as.data.frame(x)
  dat$.outcome <- y
  out <- ridgereg$new(.outcome ~ ., data=dat ,lambda = param$lambda, normalize=normalize, ...)
  
  out
}

ridge$predict <- function (modelFit, newdata, submodels = NULL) {
  if (!is.data.frame(newdata)) 
    newdata <- as.data.frame(newdata)
  newdata <- scale(newdata)
  modelFit$predict(newdata)
}

```


##5.  Find the best hyperparameter value for lambda using 10-fold cross-validation on the training set.  

```{r,eval=FALSE}
library(MASS)
fitControl <- caret::trainControl(method = "cv",
                                  number = 10)
lambdaGrid <- expand.grid(lambda = c(0,.01,.02,.03,.04))
ridge <- caret::train(crim~.,
                      data = train_data,
                      method='ridge',
                      trControl = fitControl,
                      tuneGrid = lambdaGrid,
                      preProcess=c('center', 'scale')
)
predict(ridge$finalModel, type='coef', mode='norm')$coefficients[13,]
ridge.pred <- predict(ridge, test_data)
avgErrror<-2*sqrt(mean(ridge.pred - test_data$crim)^2)
print(ridge)

```
So, **the best hyperparameter value for lambda is 0.03**

##6. Evaluate the performance of all three models on the test dataset.

By evaluating three models of 

* Linear Regression
* Linear Regression with leapForward
* Ridge Regression

Ridge regression on training set with best value of lambda gives lower RMSE.













